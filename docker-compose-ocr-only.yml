services:
  # api-gateway:
  #   build:
  #     context: api-gateway
  #     dockerfile: Dockerfile
  #   ports:
  #     - "8200:80"

  api-ocr:
    build:
      context: api-ocr
      dockerfile: Dockerfile
    command: ["uv", "run", "main_api_ocr.py"]
    ports:
      - "8204:7860"
    environment:
      - GRADIO_SERVER_PORT=7860
      - GRADIO_SERVER_NAME=0.0.0.0
      - CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672
      - CELERY_RESULT_BACKEND=rpc://
      - GRADIO_CONCURRENCY_LIMIT=10
      # FIXME check this backend works across multiple machines
    depends_on:
      rabbitmq:
        condition: service_healthy


  ocr-worker:
    build:
      context: ocr-worker
      dockerfile: test.dockerfile
      # dockerfile: Dockerfile
    command: /bin/sh -c '/app/startup.sh uv run celery --app=worker.celery worker --concurrency=1 -P threads --loglevel=INFO'
    environment: 
      - CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672
      - CELERY_RESULT_BACKEND=rpc://
    depends_on:
      rabbitmq:
        condition: service_healthy
    volumes:
      # - torch-cache:/root/.cache/torch
      - pero-models:/data/pero_ocr


  rabbitmq:
    image: rabbitmq:3.7.8
    healthcheck:
      test: ["CMD", "rabbitmqctl", "status"]
      interval: 10s
      timeout: 10s
      retries: 5

  flower:
    image: mher/flower
    ports:
      - "8205:5555"
    environment:
      - CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672
    depends_on:
      rabbitmq:
        condition: service_healthy

## TODO result backend for celery?


volumes:
  pero-models:
  # torch-cache:
